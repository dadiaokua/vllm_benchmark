#!/bin/bash

# =============================================================================
# vLLM Benchmark å¯åŠ¨è„šæœ¬
# åŒ…å«vLLMå¼•æ“å‚æ•°é…ç½®å’ŒåŸºå‡†æµ‹è¯•å‚æ•°
# =============================================================================

# ========== vLLMå¼•æ“å‚æ•° ==========
START_ENGINE="true"
MODEL_PATH="/home/llm/model_hub/Qwen2.5-32B-Instruct"
TENSOR_PARALLEL_SIZE=8
PIPELINE_PARALLEL_SIZE=1
GPU_MEMORY_UTILIZATION=0.8
MAX_MODEL_LEN=4096
MAX_NUM_SEQS=1
MAX_NUM_BATCHED_TOKENS=8192
SWAP_SPACE=0
DEVICE="cuda"
DTYPE="auto"
QUANTIZATION="None"
TRUST_REMOTE_CODE="true"
ENABLE_CHUNKED_PREFILL="false"
DISABLE_LOG_STATS="true"
ENABLE_PREFIX_CACHING="false"
SCHEDULING_POLICY="fcfs"

# ========== åŸºç¡€è¿æ¥å‚æ•° ==========
VLLM_URL="http://222.201.144.119:8000/v1"
API_KEY="test"
USE_TUNNEL=0
LOCAL_PORT="8000"
REMOTE_PORT="10085"

# ========== è¯·æ±‚é…ç½®å‚æ•° ==========
DISTRIBUTION="normal"
SHORT_QPM="50 50 60 60 80 100 150"
SHORT_CLIENT_QPM_RATIO=1
LONG_QPM="50 50 80"
LONG_CLIENT_QPM_RATIO=1

# ========== å®¢æˆ·ç«¯é…ç½®å‚æ•° ==========
SHORT_CLIENTS=7
SHORT_CLIENTS_SLO="6 7 8 9 10 11 12"
LONG_CLIENTS=3
LONG_CLIENTS_SLO="7 9 11"

# ========== å¹¶å‘å’Œæ€§èƒ½å‚æ•° ==========
CONCURRENCY=5
NUM_REQUESTS=100
REQUEST_TIMEOUT=30
SLEEP_TIME=1

# ========== å®éªŒé…ç½®å‚æ•° ==========
ROUND_NUM=20
ROUND_TIME=300
EXP_NAME="LFS"
USE_TIME_DATA=0

# ========== æ¨¡å‹å’Œtokenizerå‚æ•° ==========
TOKENIZER_PATH="/home/llm/model_hub/Qwen2.5-32B-Instruct"
REQUEST_MODEL_NAME="Qwen2.5-32B"

# ========== æ˜¾ç¤ºé…ç½®ä¿¡æ¯ ==========
echo "=========================================="
echo "         vLLM Benchmark é…ç½®ä¿¡æ¯"
echo "=========================================="
echo ""
echo "ğŸš€ vLLMå¼•æ“å‚æ•°:"
echo "  Start Engine: $START_ENGINE"
echo "  Model Path: $MODEL_PATH"
echo "  Tensor Parallel Size: $TENSOR_PARALLEL_SIZE"
echo "  Pipeline Parallel Size: $PIPELINE_PARALLEL_SIZE"
echo "  GPU Memory Utilization: $GPU_MEMORY_UTILIZATION"
echo "  Max Model Length: $MAX_MODEL_LEN"
echo "  Max Num Sequences: $MAX_NUM_SEQS"
echo "  Max Num Batched Tokens: $MAX_NUM_BATCHED_TOKENS"
echo "  Swap Space: ${SWAP_SPACE}GB"
echo "  Device: $DEVICE"
echo "  Data Type: $DTYPE"
echo "  Quantization: $QUANTIZATION"
echo "  Trust Remote Code: $TRUST_REMOTE_CODE"
echo "  Enable Chunked Prefill: $ENABLE_CHUNKED_PREFILL"
echo "  Disable Log Stats: $DISABLE_LOG_STATS"
echo "  Enable Prefix Caching: $ENABLE_PREFIX_CACHING"
echo "  Scheduling Policy: $SCHEDULING_POLICY"
echo ""
echo "ğŸ”— åŸºç¡€è¿æ¥å‚æ•°:"
echo "  vLLM URL: $VLLM_URL"
echo "  API Key: $API_KEY"
echo "  Use Tunnel: $USE_TUNNEL"
echo "  Local Port: $LOCAL_PORT"
echo "  Remote Port: $REMOTE_PORT"
echo ""
echo "ğŸ“Š è¯·æ±‚é…ç½®å‚æ•°:"
echo "  Distribution: $DISTRIBUTION"
echo "  Short QPM: $SHORT_QPM"
echo "  Short Client QPM Ratio: $SHORT_CLIENT_QPM_RATIO"
echo "  Long QPM: $LONG_QPM"
echo "  Long Client QPM Ratio: $LONG_CLIENT_QPM_RATIO"
echo ""
echo "ğŸ‘¥ å®¢æˆ·ç«¯é…ç½®å‚æ•°:"
echo "  Short Clients: $SHORT_CLIENTS"
echo "  Short Clients SLO: $SHORT_CLIENTS_SLO"
echo "  Long Clients: $LONG_CLIENTS"
echo "  Long Clients SLO: $LONG_CLIENTS_SLO"
echo ""
echo "âš¡ å¹¶å‘å’Œæ€§èƒ½å‚æ•°:"
echo "  Concurrency: $CONCURRENCY"
echo "  Num Requests: $NUM_REQUESTS"
echo "  Request Timeout: $REQUEST_TIMEOUT"
echo "  Sleep Time: $SLEEP_TIME"
echo ""
echo "ğŸ§ª å®éªŒé…ç½®å‚æ•°:"
echo "  Round Num: $ROUND_NUM"
echo "  Round Time: $ROUND_TIME"
echo "  Experiment Name: $EXP_NAME"
echo "  Use Time Data: $USE_TIME_DATA"
echo ""
echo "ğŸ¤– æ¨¡å‹å’Œtokenizerå‚æ•°:"
echo "  Tokenizer Path: $TOKENIZER_PATH"
echo "  Request Model Name: $REQUEST_MODEL_NAME"
echo ""
echo "ğŸš€ vLLMå¼•æ“å‚æ•°:"
echo "  Start Engine: $START_ENGINE"
echo "  Model Path: $MODEL_PATH"
echo "  Tensor Parallel Size: $TENSOR_PARALLEL_SIZE"
echo "  Pipeline Parallel Size: $PIPELINE_PARALLEL_SIZE"
echo "  GPU Memory Utilization: $GPU_MEMORY_UTILIZATION"
echo "  Max Model Length: $MAX_MODEL_LEN"
echo "  Max Num Sequences: $MAX_NUM_SEQS"
echo "  Max Num Batched Tokens: $MAX_NUM_BATCHED_TOKENS"
echo "  Swap Space: ${SWAP_SPACE}GB"
echo "  Device: $DEVICE"
echo "  Data Type: $DTYPE"
echo "  Quantization: $QUANTIZATION"
echo "  Trust Remote Code: $TRUST_REMOTE_CODE"
echo "  Enable Chunked Prefill: $ENABLE_CHUNKED_PREFILL"
echo "  Disable Log Stats: $DISABLE_LOG_STATS"
echo "  Scheduling Policy: $SCHEDULING_POLICY"
echo ""
echo "=========================================="
echo "æ­£åœ¨å¯åŠ¨åŸºå‡†æµ‹è¯•..."
echo "=========================================="

# ========== å¯åŠ¨åŸºå‡†æµ‹è¯• ==========
cd run_benchmark

python3 run_benchmarks.py \
    --vllm_url "$VLLM_URL" \
    --api_key "$API_KEY" \
    --use_tunnel "$USE_TUNNEL" \
    --local_port "$LOCAL_PORT" \
    --remote_port "$REMOTE_PORT" \
    --distribution "$DISTRIBUTION" \
    --short_qpm "$SHORT_QPM" \
    --short_client_qpm_ratio "$SHORT_CLIENT_QPM_RATIO" \
    --long_qpm "$LONG_QPM" \
    --long_client_qpm_ratio "$LONG_CLIENT_QPM_RATIO" \
    --short_clients "$SHORT_CLIENTS" \
    --short_clients_slo "$SHORT_CLIENTS_SLO" \
    --long_clients "$LONG_CLIENTS" \
    --long_clients_slo "$LONG_CLIENTS_SLO" \
    --concurrency "$CONCURRENCY" \
    --num_requests "$NUM_REQUESTS" \
    --request_timeout "$REQUEST_TIMEOUT" \
    --sleep "$SLEEP_TIME" \
    --round "$ROUND_NUM" \
    --round_time "$ROUND_TIME" \
    --exp "$EXP_NAME" \
    --use_time_data "$USE_TIME_DATA" \
    --tokenizer "$TOKENIZER_PATH" \
    --request_model_name "$REQUEST_MODEL_NAME" \
    --start_engine "$START_ENGINE" \
    --model_path "$MODEL_PATH" \
    --tensor_parallel_size "$TENSOR_PARALLEL_SIZE" \
    --gpu_memory_utilization "$GPU_MEMORY_UTILIZATION" \
    --max_model_len "$MAX_MODEL_LEN" \
    --max_num_seqs "$MAX_NUM_SEQS" \
    --max_num_batched_tokens "$MAX_NUM_BATCHED_TOKENS" \
    --dtype "$DTYPE" \
    --quantization "$QUANTIZATION" \
    --disable_log_stats "$DISABLE_LOG_STATS" \
    --enable_prefix_caching "$ENABLE_PREFIX_CACHING" \
    --scheduling_policy "$SCHEDULING_POLICY" 

echo ""
echo "=========================================="
echo "åŸºå‡†æµ‹è¯•å¯åŠ¨å®Œæˆï¼"
echo "=========================================="
