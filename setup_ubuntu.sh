#!/bin/bash

# =============================================================================
# Ubuntuä¸€é”®éƒ¨ç½²è„šæœ¬ - vLLMåŸºå‡†æµ‹è¯•çŽ¯å¢ƒ
# =============================================================================

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ðŸš€ å¼€å§‹UbuntuçŽ¯å¢ƒè®¾ç½®..."
echo "=========================================="

# æ£€æŸ¥æ˜¯å¦ä¸ºrootç”¨æˆ·
if [ "$EUID" -eq 0 ]; then
    echo "âŒ è¯·ä¸è¦ä»¥rootç”¨æˆ·è¿è¡Œæ­¤è„šæœ¬"
    exit 1
fi

# ========== 1. æ›´æ–°ç³»ç»Ÿ ==========
echo "ðŸ“¦ æ›´æ–°ç³»ç»ŸåŒ…..."
sudo apt update && sudo apt upgrade -y

# ========== 2. å®‰è£…åŸºç¡€å·¥å…· ==========
echo "ðŸ”§ å®‰è£…åŸºç¡€å·¥å…·..."
sudo apt install -y \
    build-essential \
    cmake \
    git \
    wget \
    curl \
    vim \
    htop \
    tmux \
    tree \
    unzip \
    software-properties-common

# ========== 3. å®‰è£…Python 3.9+ ==========
echo "ðŸ å®‰è£…Python 3.9..."
sudo apt install -y python3.9 python3.9-dev python3.9-venv python3-pip

# è®¾ç½®Pythonç‰ˆæœ¬
sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1

# ========== 4. æ£€æŸ¥NVIDIA GPU ==========
echo "ðŸ–¥ï¸ æ£€æŸ¥GPUæ”¯æŒ..."
if command -v nvidia-smi &> /dev/null; then
    echo "âœ… æ£€æµ‹åˆ°NVIDIA GPU:"
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader
else
    echo "âš ï¸ æœªæ£€æµ‹åˆ°NVIDIA GPUæˆ–é©±åŠ¨ï¼Œå°†å®‰è£…CPUç‰ˆæœ¬"
fi

# ========== 5. åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ ==========
echo "ðŸ”§ åˆ›å»ºPythonè™šæ‹ŸçŽ¯å¢ƒ..."
python3.9 -m venv vllm_env

# æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒ
source vllm_env/bin/activate

# å‡çº§pip
pip install --upgrade pip setuptools wheel

# ========== 6. å®‰è£…PyTorch ==========
echo "ðŸ”¥ å®‰è£…PyTorch..."
if command -v nvidia-smi &> /dev/null; then
    # å®‰è£…CUDAç‰ˆæœ¬
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    echo "âœ… å®‰è£…CUDAç‰ˆæœ¬PyTorch"
else
    # å®‰è£…CPUç‰ˆæœ¬
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
    echo "âœ… å®‰è£…CPUç‰ˆæœ¬PyTorch"
fi

# éªŒè¯PyTorchå®‰è£…
python -c "import torch; print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')"
if command -v nvidia-smi &> /dev/null; then
    python -c "import torch; print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}, GPUæ•°é‡: {torch.cuda.device_count()}')"
fi

# ========== 7. å®‰è£…vLLM ==========
echo "ðŸš€ å®‰è£…vLLM..."
pip install vllm

# ========== 8. å®‰è£…å…¶ä»–ä¾èµ– ==========
echo "ðŸ“š å®‰è£…å…¶ä»–ä¾èµ–..."
pip install \
    transformers \
    accelerate \
    datasets \
    numpy \
    pandas \
    matplotlib \
    seaborn \
    tqdm \
    requests \
    openai \
    aiohttp \
    psutil \
    pyyaml

# ========== 9. åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æž„ ==========
echo "ðŸ“ åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æž„..."
mkdir -p log
mkdir -p models
mkdir -p results
mkdir -p prompt_hub
mkdir -p config

# ========== 10. åˆ›å»ºç¤ºä¾‹promptæ–‡ä»¶ ==========
echo "ðŸ“ åˆ›å»ºç¤ºä¾‹promptæ–‡ä»¶..."
cat > prompt_hub/short_prompts.json << 'EOF'
[
    {"prompt": "What is the capital of France?", "max_tokens": 50},
    {"prompt": "Explain quantum computing in simple terms.", "max_tokens": 100},
    {"prompt": "Write a short poem about spring.", "max_tokens": 80},
    {"prompt": "How does photosynthesis work?", "max_tokens": 120},
    {"prompt": "What are the benefits of renewable energy?", "max_tokens": 90}
]
EOF

cat > prompt_hub/long_prompts.json << 'EOF'
[
    {"prompt": "Write a detailed essay about the impact of artificial intelligence on modern society, covering both benefits and challenges.", "max_tokens": 500},
    {"prompt": "Explain the process of photosynthesis in plants, including the chemical reactions and environmental factors involved.", "max_tokens": 400},
    {"prompt": "Describe the history and development of the internet, from its origins to modern day applications.", "max_tokens": 600}
]
EOF

# ========== 11. åˆ›å»ºé…ç½®æ–‡ä»¶ ==========
echo "âš™ï¸ åˆ›å»ºé…ç½®æ–‡ä»¶..."
cat > config/Config.py << 'EOF'
#!/usr/bin/env python3
"""
å…¨å±€é…ç½®æ–‡ä»¶
"""

GLOBAL_CONFIG = {
    'exp_time': 36000,  # å®žéªŒè¶…æ—¶æ—¶é—´(ç§’)
    'round_time': 600,  # æ¯è½®è¶…æ—¶æ—¶é—´(ç§’)
    'request_model_name': 'default-model',  # é»˜è®¤æ¨¡åž‹åç§°
    'vllm_engine': None,  # vLLMå¼•æ“Žå®žä¾‹
}

# ç»“æžœæ–‡ä»¶è·¯å¾„
RESULTS_FILE = "../results/benchmark_results.json"
EOF

# ========== 12. åˆ›å»ºrequirements.txt ==========
echo "ðŸ“‹ åˆ›å»ºrequirements.txt..."
cat > requirements.txt << 'EOF'
# vLLMå’Œç›¸å…³ä¾èµ–
vllm>=0.2.0
torch>=2.0.0
transformers>=4.30.0
accelerate>=0.20.0

# æ•°æ®å¤„ç†
numpy>=1.21.0
pandas>=1.5.0
datasets>=2.0.0

# ç½‘ç»œè¯·æ±‚
requests>=2.28.0
aiohttp>=3.8.0
openai>=0.27.0

# å¯è§†åŒ–
matplotlib>=3.5.0
seaborn>=0.11.0

# å·¥å…·åº“
tqdm>=4.64.0
psutil>=5.9.0
pyyaml>=6.0
EOF

# ========== 13. è®¾ç½®è„šæœ¬æƒé™ ==========
echo "ðŸ” è®¾ç½®è„šæœ¬æƒé™..."
chmod +x start_vllm_benchmark.sh

# ========== 14. åˆ›å»ºå¿«é€Ÿå¯åŠ¨è„šæœ¬ ==========
echo "ðŸŽ¯ åˆ›å»ºå¿«é€Ÿå¯åŠ¨è„šæœ¬..."
cat > quick_start.sh << 'EOF'
#!/bin/bash
echo "ðŸš€ å¯åŠ¨vLLMåŸºå‡†æµ‹è¯•..."
source vllm_env/bin/activate
./start_vllm_benchmark.sh
EOF
chmod +x quick_start.sh

# ========== 15. å®‰è£…ç›‘æŽ§å·¥å…· ==========
echo "ðŸ“Š å®‰è£…ç›‘æŽ§å·¥å…·..."
pip install gpustat
sudo apt install -y iotop htop

# ========== å®Œæˆå®‰è£… ==========
echo ""
echo "=========================================="
echo "ðŸŽ‰ UbuntuçŽ¯å¢ƒè®¾ç½®å®Œæˆï¼"
echo "=========================================="
echo ""
echo "ðŸ“ é¡¹ç›®ç»“æž„:"
echo "  â”œâ”€â”€ vllm_env/              # Pythonè™šæ‹ŸçŽ¯å¢ƒ"
echo "  â”œâ”€â”€ run_benchmark/         # åŸºå‡†æµ‹è¯•ä»£ç "
echo "  â”œâ”€â”€ prompt_hub/            # æµ‹è¯•promptæ•°æ®"
echo "  â”œâ”€â”€ config/                # é…ç½®æ–‡ä»¶"
echo "  â”œâ”€â”€ log/                   # æ—¥å¿—æ–‡ä»¶"
echo "  â”œâ”€â”€ results/               # ç»“æžœæ–‡ä»¶"
echo "  â”œâ”€â”€ models/                # æ¨¡åž‹æ–‡ä»¶"
echo "  â””â”€â”€ requirements.txt       # ä¾èµ–åˆ—è¡¨"
echo ""
echo "ðŸš€ ä½¿ç”¨æ–¹æ³•:"
echo "  1. æ¿€æ´»çŽ¯å¢ƒ: source vllm_env/bin/activate"
echo "  2. è¿è¡Œæµ‹è¯•: ./start_vllm_benchmark.sh"
echo "  3. æˆ–è€…ä½¿ç”¨: ./quick_start.sh (è‡ªåŠ¨æ¿€æ´»çŽ¯å¢ƒ)"
echo ""
echo "ðŸ“Š ç›‘æŽ§å·¥å…·:"
echo "  â€¢ GPUç›‘æŽ§: watch -n 1 gpustat"
echo "  â€¢ ç³»ç»Ÿç›‘æŽ§: htop"
echo "  â€¢ IOç›‘æŽ§: sudo iotop"
echo ""
echo "âš ï¸ æ³¨æ„äº‹é¡¹:"
echo "  â€¢ è¯·ç¡®ä¿æ¨¡åž‹è·¯å¾„æ­£ç¡®é…ç½®"
echo "  â€¢ æ ¹æ®GPUå†…å­˜è°ƒæ•´batch size"
echo "  â€¢ æŸ¥çœ‹æ—¥å¿—: tail -f log/run_benchmarks.log"
echo ""
echo "âœ… çŽ¯å¢ƒå‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹åŸºå‡†æµ‹è¯•äº†ï¼" 